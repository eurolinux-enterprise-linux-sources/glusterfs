From ca01872122788dd3923541590c2884c55cadf5ba Mon Sep 17 00:00:00 2001
From: Raghavendra G <rgowdapp@redhat.com>
Date: Fri, 13 May 2016 11:40:57 +0530
Subject: [PATCH 158/158] cluster/distribute: heal layout in discover codepath too

BUG: 1325760
Change-Id: I4259d88f2b6e4f9d4ad689bc4e438f1db9cfd177
Signed-off-by: Raghavendra G <rgowdapp@redhat.com>
Reviewed-on: http://review.gluster.org/14365
Tested-by: Pranith Kumar Karampuri <pkarampu@redhat.com>
Smoke: Gluster Build System <jenkins@build.gluster.com>
NetBSD-regression: NetBSD Build System <jenkins@build.gluster.org>
CentOS-regression: Gluster Build System <jenkins@build.gluster.com>
Reviewed-on: https://code.engineering.redhat.com/gerrit/74435
---
 tests/bugs/distribute/bug-1088231.t  |   14 +++++++++++-
 xlators/cluster/dht/src/dht-common.c |   40 ++++++----------------------------
 2 files changed, 20 insertions(+), 34 deletions(-)

diff --git a/tests/bugs/distribute/bug-1088231.t b/tests/bugs/distribute/bug-1088231.t
index b2347ef..8d4d1db 100755
--- a/tests/bugs/distribute/bug-1088231.t
+++ b/tests/bugs/distribute/bug-1088231.t
@@ -31,6 +31,11 @@ gfid_with_hyphen=`getfattr -n glusterfs.gfid.string $M0/a 2>/dev/null \
 
 TEST setfattr -x trusted.glusterfs.dht $B0/$V0"0"/a
 
+## new healing code don't attempt healing if inode is already
+## populated. So, unmount and remount before we do stat.
+TEST umount $M0
+TEST glusterfs --volfile-id=/$V0 --aux-gfid-mount --volfile-server=$H0 $M0
+
 TEST stat $M0/.gfid/$gfid_with_hyphen
 
 ##  Assuming that we have two bricks, we can have two permutations of layout
@@ -57,6 +62,8 @@ TEST stat $M0/.gfid/$gfid_with_hyphen
 
 
 ##Extract Layout
+echo `get_layout  $B0/$V0"0"/a`
+echo `get_layout  $B0/$V0"1"/a`
 layout_b0_s=`get_layout $B0/$V0"0"/a  | cut -c19-26`
 layout_b0_e=`get_layout $B0/$V0"0"/a  | cut -c27-34`
 layout_b1_s=`get_layout $B0/$V0"1"/a  | cut -c19-26`
@@ -70,7 +77,6 @@ layout_b1_s="0x"$layout_b1_s
 layout_b1_e="0x"$layout_b1_e
 
 
-
 ## Logic of converting starting layout "0" to "Max_value of layout + 1"
 comp1=$(($layout_b0_s + 0))
 if [ "$comp1" == "0" ];then
@@ -114,9 +120,15 @@ gfid_with_hyphen=`getfattr -n glusterfs.gfid.string $M0/a 2>/dev/null \
 TEST setfattr -x trusted.glusterfs.dht $B0/$V0"0"/a
 TEST setfattr -x trusted.glusterfs.dht $B0/$V0"1"/a
 
+## new healing code don't attempt healing if inode is already
+## populated. So, unmount and remount before we do stat.
+TEST umount $M0
+TEST glusterfs --volfile-id=/$V0 --aux-gfid-mount --volfile-server=$H0 $M0
+
 TEST stat $M0/.gfid/$gfid_with_hyphen
 
 ##Extract Layout
+
 layout_b0_s=`get_layout $B0/$V0"0"/a  | cut -c19-26`
 layout_b0_e=`get_layout $B0/$V0"0"/a  | cut -c27-34`
 layout_b1_s=`get_layout $B0/$V0"1"/a  | cut -c19-26`
diff --git a/xlators/cluster/dht/src/dht-common.c b/xlators/cluster/dht/src/dht-common.c
index 10d47de..ebf074c 100644
--- a/xlators/cluster/dht/src/dht-common.c
+++ b/xlators/cluster/dht/src/dht-common.c
@@ -255,7 +255,7 @@ dht_discover_complete (xlator_t *this, call_frame_t *discover_frame)
         int              heal_path       = 0;
         int              i               = 0;
         loc_t            loc             = {0 };
-        int8_t           is_read_only    = 0;
+        int8_t           is_read_only    = 0, layout_anomalies = 0;
 
         local = discover_frame->local;
         layout = local->layout;
@@ -310,26 +310,10 @@ dht_discover_complete (xlator_t *this, call_frame_t *discover_frame)
                                       "(overlaps/holes present: %s, "
                                       "ENOENT errors: %d)", local->loc.path,
                                       (ret < 0) ? "yes" : "no", (ret > 0) ? ret : 0);
-                        if ((ret > 0) && (ret == conf->subvolume_cnt)) {
-                                op_errno = ESTALE;
-                                goto out;
-                        }
-
-                        /* For fixing the directory layout, we need to choose
-                         * the subvolume on which layout will be set first.
-                         * Because in nameless lookup, we have gfid only,
-                         * we are dependent on gfid. Therefore if conf->
-                         * randomize_by_gfid is set, then only we proceed for
-                         * healing layout of directory otherwise we don't heal.
-                         */
-
-                        if (local->inode && conf->randomize_by_gfid &&
-                            !is_read_only)
-                                goto selfheal;
-                }
-
-                if (local->inode)
+                        layout_anomalies = 1;
+                } else if (local->inode) {
                         dht_layout_set (this, local->inode, layout);
+                }
         }
 
         if (!conf->vch_forced) {
@@ -349,11 +333,13 @@ dht_discover_complete (xlator_t *this, call_frame_t *discover_frame)
                             layout->list[i].err == ESTALE) {
                                 heal_path = 1;
                         }
+
                         if (source && heal_path)
                                 break;
                 }
         }
-        if (source && heal_path) {
+
+        if (source && (heal_path || layout_anomalies)) {
                 gf_uuid_copy (loc.gfid, local->gfid);
                 if (gf_uuid_is_null (loc.gfid)) {
                         goto done;
@@ -408,18 +394,6 @@ out:
                           NULL);
 
         return ret;
-
-selfheal:
-
-        main_frame->local = local;
-        discover_frame->local =  NULL;
-        FRAME_SU_DO (main_frame, dht_local_t);
-        gf_uuid_copy (local->loc.gfid, local->gfid);
-        ret = dht_selfheal_directory_for_nameless_lookup (main_frame,
-                                                        dht_lookup_selfheal_cbk,
-                                                          &local->loc, layout);
-        return ret;
-
 }
 
 int
-- 
1.7.1

